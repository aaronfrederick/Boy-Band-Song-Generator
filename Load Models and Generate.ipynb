{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/aaronfrederick/Desktop/venv/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, GRU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.layers import Embedding\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For blog post, use epochs:\n",
    "-5\n",
    "-25\n",
    "-70\n",
    "-80\n",
    "-110\n",
    "-140 THRU 150\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))\n",
    "\n",
    "#Initialize Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(5405, output_dim=50, input_length=6))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(5405, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence(seed, model=model, tokenizer=tokenizer, length=6, n_words=70):\n",
    "    result = []\n",
    "    in_word = seed\n",
    "    for _ in range(n_words):\n",
    "        encoded = tokenizer.texts_to_sequences([in_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=length, truncating='pre')\n",
    "        pred = model.predict_classes(encoded)\n",
    "        out = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index==pred:\n",
    "                out = word\n",
    "                break\n",
    "        in_word += ' ' + out\n",
    "        result.append(out)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come on no other no other no more no more\n",
      "dont let me go dont let me go dont let\n",
      "cant deny we can be our boy boy i know\n",
      "to run some people know that were not gonna wait\n",
      "me that you love me but you dont have to\n",
      "before we were eighteen be another night for the light\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('models/weights.140-2.64-bigger.hdf5')\n",
    "\n",
    "print(gen_sequence('me', n_words=10))\n",
    "print(gen_sequence('why', n_words=10))\n",
    "print(gen_sequence('we', n_words=10))\n",
    "print(gen_sequence('us', n_words=10))\n",
    "print(gen_sequence('tell', n_words=10))\n",
    "print(gen_sequence('trust', n_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come on no other no other no more no more no more no more no more no more no more no more no more no more no more no more\n",
      "dont let me go dont let me go dont let me go dont let me go dont let me go dont let me go dont let me go dont let\n",
      "cant deny we can be our boy boy i know i know i know i know i know i know i know i know i know i know i know\n",
      "to run some people know that were not gonna wait im gonna be your so place but it was so many times i wanna take that to show you im\n",
      "me that you love me but you dont have to worry when the weather come on now i know you want to be money thats the answer cause you got\n",
      "before we were eighteen be another night for the light on the new kids down the block party were so young wait on fire oh oh oh oh oh oh\n"
     ]
    }
   ],
   "source": [
    "print(gen_sequence('me', n_words=30))\n",
    "print(gen_sequence('why', n_words=30))\n",
    "print(gen_sequence('we', n_words=30))\n",
    "print(gen_sequence('us', n_words=30))\n",
    "print(gen_sequence('tell', n_words=30))\n",
    "print(gen_sequence('trust', n_words=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
