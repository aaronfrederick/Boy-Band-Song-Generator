{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/aaronfrederick/Desktop/venv/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Flatten, GRU\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import re\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pickle.load(open('corpus.pkl', 'rb'))\n",
    "cleaned = [re.sub('[^a-zA-Z ]', '', song) for song in corpus]\n",
    "\n",
    "cleaned = list(set(cleaned))\n",
    "tokens = [song.split() for song in cleaned]\n",
    "\n",
    "words = []\n",
    "for song in cleaned:\n",
    "    for word in song.split():\n",
    "        words.append(word)\n",
    "\n",
    "lines = []\n",
    "for i in range(len(words)-7):\n",
    "    lines.append(words[i:i+7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_unique = []\n",
    "# for line in tqdm(lines):\n",
    "#     if line not in lines_unique:\n",
    "#         lines_unique.append(line)\n",
    "\n",
    "# len(lines_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(lines_unique, open('unique_lines.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_unique = pickle.load(open('unique_lines.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn words to ints\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines_unique)\n",
    "sequences = tokenizer.texts_to_sequences(lines_unique)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143265, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model *DONT USE DROPOUT - DEPENDENCY ERROR*\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, output_dim=50, input_length=seq_length))\n",
    "model.add(GRU(256, return_sequences=True))\n",
    "model.add(GRU(256))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 6, 50)             270250    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 6, 256)            235776    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5405)              545905    \n",
      "=================================================================\n",
      "Total params: 1,471,615\n",
      "Trainable params: 1,471,615\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd = optimizers.SGD(lr=0.1, decay=0, momentum=0.05, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "143265/143265 [==============================] - 94s 659us/step - loss: 6.8062 - acc: 0.0435\n",
      "Epoch 2/150\n",
      "143265/143265 [==============================] - 94s 658us/step - loss: 6.0311 - acc: 0.0424\n",
      "Epoch 3/150\n",
      "143265/143265 [==============================] - 94s 657us/step - loss: 6.0097 - acc: 0.0438\n",
      "Epoch 4/150\n",
      "143265/143265 [==============================] - 104s 728us/step - loss: 6.0004 - acc: 0.0443\n",
      "Epoch 5/150\n",
      "143265/143265 [==============================] - 137s 953us/step - loss: 5.9917 - acc: 0.0450\n",
      "\n",
      "Epoch 00005: saving model to models/weights.05-5.99-bigger.hdf5\n",
      "Epoch 6/150\n",
      "143265/143265 [==============================] - 208s 1ms/step - loss: 5.9842 - acc: 0.0448\n",
      "Epoch 7/150\n",
      "143265/143265 [==============================] - 192s 1ms/step - loss: 5.9785 - acc: 0.0449\n",
      "Epoch 8/150\n",
      "143265/143265 [==============================] - 172s 1ms/step - loss: 5.9708 - acc: 0.0461\n",
      "Epoch 9/150\n",
      "143265/143265 [==============================] - 143s 1ms/step - loss: 5.9600 - acc: 0.0462\n",
      "Epoch 10/150\n",
      "143265/143265 [==============================] - 152s 1ms/step - loss: 5.9433 - acc: 0.0470\n",
      "\n",
      "Epoch 00010: saving model to models/weights.10-5.94-bigger.hdf5\n",
      "Epoch 11/150\n",
      "143265/143265 [==============================] - 152s 1ms/step - loss: 5.9075 - acc: 0.0484\n",
      "Epoch 12/150\n",
      "143265/143265 [==============================] - 156s 1ms/step - loss: 5.8488 - acc: 0.0519\n",
      "Epoch 13/150\n",
      "143265/143265 [==============================] - 154s 1ms/step - loss: 5.7925 - acc: 0.0544\n",
      "Epoch 14/150\n",
      "143265/143265 [==============================] - 159s 1ms/step - loss: 5.7483 - acc: 0.0556\n",
      "Epoch 15/150\n",
      "143265/143265 [==============================] - 161s 1ms/step - loss: 5.7127 - acc: 0.0556\n",
      "\n",
      "Epoch 00015: saving model to models/weights.15-5.71-bigger.hdf5\n",
      "Epoch 16/150\n",
      "143265/143265 [==============================] - 141s 985us/step - loss: 5.6685 - acc: 0.0574\n",
      "Epoch 17/150\n",
      "143265/143265 [==============================] - 116s 809us/step - loss: 5.5958 - acc: 0.0625\n",
      "Epoch 18/150\n",
      "143265/143265 [==============================] - 117s 819us/step - loss: 5.5306 - acc: 0.0675\n",
      "Epoch 19/150\n",
      "143265/143265 [==============================] - 116s 809us/step - loss: 5.4771 - acc: 0.0744\n",
      "Epoch 20/150\n",
      "143265/143265 [==============================] - 117s 818us/step - loss: 5.4319 - acc: 0.0788\n",
      "\n",
      "Epoch 00020: saving model to models/weights.20-5.43-bigger.hdf5\n",
      "Epoch 21/150\n",
      "143265/143265 [==============================] - 115s 801us/step - loss: 5.3906 - acc: 0.0842\n",
      "Epoch 22/150\n",
      "143265/143265 [==============================] - 134s 934us/step - loss: 5.3534 - acc: 0.0893\n",
      "Epoch 23/150\n",
      "143265/143265 [==============================] - 112s 785us/step - loss: 5.3198 - acc: 0.0930\n",
      "Epoch 24/150\n",
      "143265/143265 [==============================] - 117s 817us/step - loss: 5.2891 - acc: 0.0962\n",
      "Epoch 25/150\n",
      "143265/143265 [==============================] - 112s 781us/step - loss: 5.2593 - acc: 0.0980\n",
      "\n",
      "Epoch 00025: saving model to models/weights.25-5.26-bigger.hdf5\n",
      "Epoch 26/150\n",
      "143265/143265 [==============================] - 112s 780us/step - loss: 5.2320 - acc: 0.1014\n",
      "Epoch 27/150\n",
      "143265/143265 [==============================] - 111s 773us/step - loss: 5.2048 - acc: 0.1025\n",
      "Epoch 28/150\n",
      "143265/143265 [==============================] - 112s 780us/step - loss: 5.1778 - acc: 0.1051\n",
      "Epoch 29/150\n",
      "143265/143265 [==============================] - 111s 773us/step - loss: 5.1538 - acc: 0.1073\n",
      "Epoch 30/150\n",
      "143265/143265 [==============================] - 110s 769us/step - loss: 5.1302 - acc: 0.1092\n",
      "\n",
      "Epoch 00030: saving model to models/weights.30-5.13-bigger.hdf5\n",
      "Epoch 31/150\n",
      "143265/143265 [==============================] - 121s 846us/step - loss: 5.1076 - acc: 0.1100\n",
      "Epoch 32/150\n",
      "143265/143265 [==============================] - 109s 760us/step - loss: 5.0864 - acc: 0.1107\n",
      "Epoch 33/150\n",
      "143265/143265 [==============================] - 111s 776us/step - loss: 5.0646 - acc: 0.1125\n",
      "Epoch 34/150\n",
      "143265/143265 [==============================] - 109s 762us/step - loss: 5.0434 - acc: 0.1138\n",
      "Epoch 35/150\n",
      "143265/143265 [==============================] - 113s 786us/step - loss: 5.0214 - acc: 0.1155\n",
      "\n",
      "Epoch 00035: saving model to models/weights.35-5.02-bigger.hdf5\n",
      "Epoch 36/150\n",
      "143265/143265 [==============================] - 113s 791us/step - loss: 5.0004 - acc: 0.1180\n",
      "Epoch 37/150\n",
      "143265/143265 [==============================] - 110s 768us/step - loss: 4.9794 - acc: 0.1189\n",
      "Epoch 38/150\n",
      "143265/143265 [==============================] - 113s 792us/step - loss: 4.9574 - acc: 0.1206\n",
      "Epoch 39/150\n",
      "143265/143265 [==============================] - 112s 779us/step - loss: 4.9369 - acc: 0.1229\n",
      "Epoch 40/150\n",
      "143265/143265 [==============================] - 121s 845us/step - loss: 4.9145 - acc: 0.1245\n",
      "\n",
      "Epoch 00040: saving model to models/weights.40-4.91-bigger.hdf5\n",
      "Epoch 41/150\n",
      "143265/143265 [==============================] - 111s 772us/step - loss: 4.8953 - acc: 0.1258\n",
      "Epoch 42/150\n",
      "143265/143265 [==============================] - 114s 793us/step - loss: 4.8728 - acc: 0.1290\n",
      "Epoch 43/150\n",
      "143265/143265 [==============================] - 110s 764us/step - loss: 4.8516 - acc: 0.1301\n",
      "Epoch 44/150\n",
      "143265/143265 [==============================] - 112s 784us/step - loss: 4.8299 - acc: 0.1322\n",
      "Epoch 45/150\n",
      "143265/143265 [==============================] - 102s 712us/step - loss: 4.8099 - acc: 0.1332\n",
      "\n",
      "Epoch 00045: saving model to models/weights.45-4.81-bigger.hdf5\n",
      "Epoch 46/150\n",
      "143265/143265 [==============================] - 99s 694us/step - loss: 4.7891 - acc: 0.1344\n",
      "Epoch 47/150\n",
      "143265/143265 [==============================] - 103s 717us/step - loss: 4.7664 - acc: 0.1371\n",
      "Epoch 48/150\n",
      "143265/143265 [==============================] - 100s 699us/step - loss: 4.7451 - acc: 0.1393\n",
      "Epoch 49/150\n",
      "143265/143265 [==============================] - 102s 709us/step - loss: 4.7240 - acc: 0.1411\n",
      "Epoch 50/150\n",
      "143265/143265 [==============================] - 107s 743us/step - loss: 4.7037 - acc: 0.1422\n",
      "\n",
      "Epoch 00050: saving model to models/weights.50-4.70-bigger.hdf5\n",
      "Epoch 51/150\n",
      "143265/143265 [==============================] - 104s 724us/step - loss: 4.6826 - acc: 0.1442\n",
      "Epoch 52/150\n",
      "143265/143265 [==============================] - 104s 724us/step - loss: 4.6603 - acc: 0.1474\n",
      "Epoch 53/150\n",
      "143265/143265 [==============================] - 105s 733us/step - loss: 4.6392 - acc: 0.1486\n",
      "Epoch 54/150\n",
      "143265/143265 [==============================] - 113s 788us/step - loss: 4.6188 - acc: 0.1508\n",
      "Epoch 55/150\n",
      "143265/143265 [==============================] - 104s 723us/step - loss: 4.5970 - acc: 0.1521\n",
      "\n",
      "Epoch 00055: saving model to models/weights.55-4.60-bigger.hdf5\n",
      "Epoch 56/150\n",
      "143265/143265 [==============================] - 106s 737us/step - loss: 4.5741 - acc: 0.1549\n",
      "Epoch 57/150\n",
      "143265/143265 [==============================] - 100s 696us/step - loss: 4.5548 - acc: 0.1571\n",
      "Epoch 58/150\n",
      "143265/143265 [==============================] - 101s 705us/step - loss: 4.5336 - acc: 0.1582\n",
      "Epoch 59/150\n",
      "143265/143265 [==============================] - 107s 744us/step - loss: 4.5121 - acc: 0.1610\n",
      "Epoch 60/150\n",
      "143265/143265 [==============================] - 106s 737us/step - loss: 4.4922 - acc: 0.1621\n",
      "\n",
      "Epoch 00060: saving model to models/weights.60-4.49-bigger.hdf5\n",
      "Epoch 61/150\n",
      "143265/143265 [==============================] - 105s 730us/step - loss: 4.4709 - acc: 0.1643\n",
      "Epoch 62/150\n",
      "143265/143265 [==============================] - 105s 734us/step - loss: 4.4521 - acc: 0.1658\n",
      "Epoch 63/150\n",
      "143265/143265 [==============================] - 103s 718us/step - loss: 4.4309 - acc: 0.1676\n",
      "Epoch 64/150\n",
      "143265/143265 [==============================] - 100s 695us/step - loss: 4.4092 - acc: 0.1704\n",
      "Epoch 65/150\n",
      "143265/143265 [==============================] - 108s 754us/step - loss: 4.3897 - acc: 0.1709\n",
      "\n",
      "Epoch 00065: saving model to models/weights.65-4.39-bigger.hdf5\n",
      "Epoch 66/150\n",
      "143265/143265 [==============================] - 99s 691us/step - loss: 4.3687 - acc: 0.1742\n",
      "Epoch 67/150\n",
      "143265/143265 [==============================] - 102s 709us/step - loss: 4.3477 - acc: 0.1752\n",
      "Epoch 68/150\n",
      "143265/143265 [==============================] - 111s 773us/step - loss: 4.3280 - acc: 0.1778\n",
      "Epoch 69/150\n",
      "143265/143265 [==============================] - 109s 758us/step - loss: 4.3067 - acc: 0.1791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150\n",
      "143265/143265 [==============================] - 102s 712us/step - loss: 4.2872 - acc: 0.1812\n",
      "\n",
      "Epoch 00070: saving model to models/weights.70-4.29-bigger.hdf5\n",
      "Epoch 71/150\n",
      "143265/143265 [==============================] - 97s 679us/step - loss: 4.2679 - acc: 0.1836\n",
      "Epoch 72/150\n",
      "143265/143265 [==============================] - 98s 682us/step - loss: 4.2460 - acc: 0.1860\n",
      "Epoch 73/150\n",
      "143265/143265 [==============================] - 95s 664us/step - loss: 4.2246 - acc: 0.1878\n",
      "Epoch 74/150\n",
      "143265/143265 [==============================] - 107s 748us/step - loss: 4.2058 - acc: 0.1894\n",
      "Epoch 75/150\n",
      "143265/143265 [==============================] - 108s 753us/step - loss: 4.1844 - acc: 0.1926\n",
      "\n",
      "Epoch 00075: saving model to models/weights.75-4.18-bigger.hdf5\n",
      "Epoch 76/150\n",
      "143265/143265 [==============================] - 105s 731us/step - loss: 4.1648 - acc: 0.1938\n",
      "Epoch 77/150\n",
      "143265/143265 [==============================] - 96s 672us/step - loss: 4.1427 - acc: 0.1966\n",
      "Epoch 78/150\n",
      "143265/143265 [==============================] - 96s 671us/step - loss: 4.1226 - acc: 0.1997\n",
      "Epoch 79/150\n",
      "143265/143265 [==============================] - 96s 667us/step - loss: 4.1021 - acc: 0.2011\n",
      "Epoch 80/150\n",
      "143265/143265 [==============================] - 93s 648us/step - loss: 4.0796 - acc: 0.2028\n",
      "\n",
      "Epoch 00080: saving model to models/weights.80-4.08-bigger.hdf5\n",
      "Epoch 81/150\n",
      "143265/143265 [==============================] - 107s 744us/step - loss: 4.0600 - acc: 0.2056\n",
      "Epoch 82/150\n",
      "143265/143265 [==============================] - 106s 742us/step - loss: 4.0388 - acc: 0.2085\n",
      "Epoch 83/150\n",
      "143265/143265 [==============================] - 107s 745us/step - loss: 4.0169 - acc: 0.2099\n",
      "Epoch 84/150\n",
      "143265/143265 [==============================] - 99s 689us/step - loss: 3.9966 - acc: 0.2113\n",
      "Epoch 85/150\n",
      "143265/143265 [==============================] - 95s 666us/step - loss: 3.9742 - acc: 0.2155\n",
      "\n",
      "Epoch 00085: saving model to models/weights.85-3.97-bigger.hdf5\n",
      "Epoch 86/150\n",
      "143265/143265 [==============================] - 101s 702us/step - loss: 3.9528 - acc: 0.2167\n",
      "Epoch 87/150\n",
      "143265/143265 [==============================] - 105s 733us/step - loss: 3.9320 - acc: 0.2207\n",
      "Epoch 88/150\n",
      "143265/143265 [==============================] - 104s 727us/step - loss: 3.9095 - acc: 0.2231\n",
      "Epoch 89/150\n",
      "143265/143265 [==============================] - 104s 725us/step - loss: 3.8884 - acc: 0.2246\n",
      "Epoch 90/150\n",
      "143265/143265 [==============================] - 101s 702us/step - loss: 3.8673 - acc: 0.2271\n",
      "\n",
      "Epoch 00090: saving model to models/weights.90-3.87-bigger.hdf5\n",
      "Epoch 91/150\n",
      "143265/143265 [==============================] - 99s 694us/step - loss: 3.8440 - acc: 0.2298\n",
      "Epoch 92/150\n",
      "143265/143265 [==============================] - 95s 665us/step - loss: 3.8235 - acc: 0.2324\n",
      "Epoch 93/150\n",
      "143265/143265 [==============================] - 95s 665us/step - loss: 3.8001 - acc: 0.2357\n",
      "Epoch 94/150\n",
      "143265/143265 [==============================] - 101s 707us/step - loss: 3.7779 - acc: 0.2386\n",
      "Epoch 95/150\n",
      "143265/143265 [==============================] - 103s 716us/step - loss: 3.7534 - acc: 0.2406\n",
      "\n",
      "Epoch 00095: saving model to models/weights.95-3.75-bigger.hdf5\n",
      "Epoch 96/150\n",
      "143265/143265 [==============================] - 102s 713us/step - loss: 3.7350 - acc: 0.2428\n",
      "Epoch 97/150\n",
      "143265/143265 [==============================] - 104s 724us/step - loss: 3.7130 - acc: 0.2455\n",
      "Epoch 98/150\n",
      "143265/143265 [==============================] - 104s 727us/step - loss: 3.6880 - acc: 0.2492\n",
      "Epoch 99/150\n",
      "143265/143265 [==============================] - 103s 717us/step - loss: 3.6653 - acc: 0.2521\n",
      "Epoch 100/150\n",
      "143265/143265 [==============================] - 99s 691us/step - loss: 3.6422 - acc: 0.2543\n",
      "\n",
      "Epoch 00100: saving model to models/weights.100-3.64-bigger.hdf5\n",
      "Epoch 101/150\n",
      "143265/143265 [==============================] - 105s 733us/step - loss: 3.6167 - acc: 0.2577\n",
      "Epoch 102/150\n",
      "143265/143265 [==============================] - 103s 720us/step - loss: 3.5955 - acc: 0.2613\n",
      "Epoch 103/150\n",
      "143265/143265 [==============================] - 97s 675us/step - loss: 3.5729 - acc: 0.2633\n",
      "Epoch 104/150\n",
      "143265/143265 [==============================] - 100s 696us/step - loss: 3.5502 - acc: 0.2658\n",
      "Epoch 105/150\n",
      "143265/143265 [==============================] - 112s 779us/step - loss: 3.5284 - acc: 0.2688\n",
      "\n",
      "Epoch 00105: saving model to models/weights.105-3.53-bigger.hdf5\n",
      "Epoch 106/150\n",
      "143265/143265 [==============================] - 101s 703us/step - loss: 3.5026 - acc: 0.2717\n",
      "Epoch 107/150\n",
      "143265/143265 [==============================] - 100s 697us/step - loss: 3.4788 - acc: 0.2745\n",
      "Epoch 108/150\n",
      "143265/143265 [==============================] - 100s 700us/step - loss: 3.4570 - acc: 0.2786\n",
      "Epoch 109/150\n",
      "143265/143265 [==============================] - 103s 718us/step - loss: 3.4327 - acc: 0.2817\n",
      "Epoch 110/150\n",
      "143265/143265 [==============================] - 110s 768us/step - loss: 3.4089 - acc: 0.2847\n",
      "\n",
      "Epoch 00110: saving model to models/weights.110-3.41-bigger.hdf5\n",
      "Epoch 111/150\n",
      "143265/143265 [==============================] - 114s 793us/step - loss: 3.3845 - acc: 0.2896\n",
      "Epoch 112/150\n",
      "143265/143265 [==============================] - 105s 730us/step - loss: 3.3617 - acc: 0.2914\n",
      "Epoch 113/150\n",
      "143265/143265 [==============================] - 101s 707us/step - loss: 3.3338 - acc: 0.2944\n",
      "Epoch 114/150\n",
      "143265/143265 [==============================] - 101s 705us/step - loss: 3.3115 - acc: 0.2977\n",
      "Epoch 115/150\n",
      "143265/143265 [==============================] - 101s 706us/step - loss: 3.2853 - acc: 0.3031\n",
      "\n",
      "Epoch 00115: saving model to models/weights.115-3.29-bigger.hdf5\n",
      "Epoch 116/150\n",
      "143265/143265 [==============================] - 102s 710us/step - loss: 3.2611 - acc: 0.3047\n",
      "Epoch 117/150\n",
      "143265/143265 [==============================] - 101s 704us/step - loss: 3.2365 - acc: 0.3081\n",
      "Epoch 118/150\n",
      "143265/143265 [==============================] - 107s 745us/step - loss: 3.2123 - acc: 0.3129\n",
      "Epoch 119/150\n",
      "143265/143265 [==============================] - 112s 781us/step - loss: 3.1873 - acc: 0.3168\n",
      "Epoch 120/150\n",
      "143265/143265 [==============================] - 114s 794us/step - loss: 3.1609 - acc: 0.3201\n",
      "\n",
      "Epoch 00120: saving model to models/weights.120-3.16-bigger.hdf5\n",
      "Epoch 121/150\n",
      "143265/143265 [==============================] - 98s 688us/step - loss: 3.1374 - acc: 0.3244\n",
      "Epoch 122/150\n",
      "143265/143265 [==============================] - 99s 688us/step - loss: 3.1125 - acc: 0.3268\n",
      "Epoch 123/150\n",
      "143265/143265 [==============================] - 97s 675us/step - loss: 3.0874 - acc: 0.3303\n",
      "Epoch 124/150\n",
      "143265/143265 [==============================] - 98s 687us/step - loss: 3.0619 - acc: 0.3348\n",
      "Epoch 125/150\n",
      "143265/143265 [==============================] - 99s 690us/step - loss: 3.0350 - acc: 0.3392\n",
      "\n",
      "Epoch 00125: saving model to models/weights.125-3.03-bigger.hdf5\n",
      "Epoch 126/150\n",
      "143265/143265 [==============================] - 96s 672us/step - loss: 3.0114 - acc: 0.3435\n",
      "Epoch 127/150\n",
      "143265/143265 [==============================] - 100s 700us/step - loss: 2.9810 - acc: 0.3477\n",
      "Epoch 128/150\n",
      "143265/143265 [==============================] - 98s 686us/step - loss: 2.9611 - acc: 0.3497\n",
      "Epoch 129/150\n",
      "143265/143265 [==============================] - 99s 688us/step - loss: 2.9329 - acc: 0.3562\n",
      "Epoch 130/150\n",
      "143265/143265 [==============================] - 100s 696us/step - loss: 2.9086 - acc: 0.3592\n",
      "\n",
      "Epoch 00130: saving model to models/weights.130-2.91-bigger.hdf5\n",
      "Epoch 131/150\n",
      "143265/143265 [==============================] - 97s 680us/step - loss: 2.8830 - acc: 0.3632\n",
      "Epoch 132/150\n",
      "143265/143265 [==============================] - 92s 642us/step - loss: 2.8569 - acc: 0.3677\n",
      "Epoch 133/150\n",
      "143265/143265 [==============================] - 92s 641us/step - loss: 2.8308 - acc: 0.3715\n",
      "Epoch 134/150\n",
      "143265/143265 [==============================] - 92s 642us/step - loss: 2.8031 - acc: 0.3766\n",
      "Epoch 135/150\n",
      "143265/143265 [==============================] - 98s 681us/step - loss: 2.7777 - acc: 0.3806\n",
      "\n",
      "Epoch 00135: saving model to models/weights.135-2.78-bigger.hdf5\n",
      "Epoch 136/150\n",
      "143265/143265 [==============================] - 96s 673us/step - loss: 2.7492 - acc: 0.3866\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143265/143265 [==============================] - 93s 648us/step - loss: 2.7243 - acc: 0.3897\n",
      "Epoch 138/150\n",
      "143265/143265 [==============================] - 92s 640us/step - loss: 2.7002 - acc: 0.3939\n",
      "Epoch 139/150\n",
      "143265/143265 [==============================] - 91s 632us/step - loss: 2.6704 - acc: 0.4000\n",
      "Epoch 140/150\n",
      "143265/143265 [==============================] - 90s 631us/step - loss: 2.6437 - acc: 0.4036\n",
      "\n",
      "Epoch 00140: saving model to models/weights.140-2.64-bigger.hdf5\n",
      "Epoch 141/150\n",
      "143265/143265 [==============================] - 91s 632us/step - loss: 2.6202 - acc: 0.4088\n",
      "Epoch 142/150\n",
      "143265/143265 [==============================] - 91s 632us/step - loss: 2.5916 - acc: 0.4128\n",
      "Epoch 143/150\n",
      "143265/143265 [==============================] - 91s 632us/step - loss: 2.5623 - acc: 0.4173\n",
      "Epoch 144/150\n",
      "143265/143265 [==============================] - 90s 631us/step - loss: 2.5390 - acc: 0.4219\n",
      "Epoch 145/150\n",
      "143265/143265 [==============================] - 91s 633us/step - loss: 2.5134 - acc: 0.4266\n",
      "\n",
      "Epoch 00145: saving model to models/weights.145-2.51-bigger.hdf5\n",
      "Epoch 146/150\n",
      "143265/143265 [==============================] - 100s 699us/step - loss: 2.4831 - acc: 0.4311\n",
      "Epoch 147/150\n",
      "143265/143265 [==============================] - 97s 679us/step - loss: 2.4583 - acc: 0.4369\n",
      "Epoch 148/150\n",
      "143265/143265 [==============================] - 102s 715us/step - loss: 2.4318 - acc: 0.4417\n",
      "Epoch 149/150\n",
      "143265/143265 [==============================] - 93s 651us/step - loss: 2.4062 - acc: 0.4453\n",
      "Epoch 150/150\n",
      "143265/143265 [==============================] - 91s 638us/step - loss: 2.3770 - acc: 0.4511\n",
      "\n",
      "Epoch 00150: saving model to models/weights.150-2.38-bigger.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129097ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"models/weights.{epoch:02d}-{loss:.2f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=False, mode=\"min\", period = 5)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X, y, batch_size=256, epochs=150, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
